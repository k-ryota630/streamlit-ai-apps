import os
import streamlit as st
import google.generativeai as genai
from google.generativeai.types import HarmCategory, HarmBlockThreshold

# Google API Keyã®è¨­å®š
api_key = os.getenv("GOOGLE_API_KEY")
if not api_key:
    st.error("GOOGLE_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚Streamlit Cloudã«APIã‚­ãƒ¼ãŒç™»éŒ²ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    st.stop()

genai.configure(api_key=api_key)

# Gemini ãƒ¢ãƒ‡ãƒ«ã®æŒ‡å®š
MODEL_ID = "gemini-2.5-pro-exp-03-25"
generation_config = {
    "temperature": 0.7,
    "top_p": 0.95,
    "top_k": 0,
    "max_output_tokens": 2048,
}

safety_settings=None

def main():
    # Streamlitãƒšãƒ¼ã‚¸è¨­å®š
    st.set_page_config(page_title="My Great Gemini 2.5 Pro", page_icon="ğŸ¤—")
    st.header("My Great Gemini 2.5 Pro ğŸ¤—")

    # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’é–¢æ•°ã®å…ˆé ­ã§å®šç¾©
    system_prompt = "You are a helpful assistant."

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´åˆæœŸåŒ–
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’ç”»é¢ã«è¡¨ç¤º
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã®å—ä»˜
    user_input = st.chat_input("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    if user_input:
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã¨ç”»é¢ã«è¿½åŠ 
        st.session_state.messages.append({"role": "user", "content": user_input})
        with st.chat_message("user"):
            st.markdown(user_input)

        # Geminiãƒ¢ãƒ‡ãƒ«ã®æº–å‚™
        model = genai.GenerativeModel(
            model_name="gemini-2.5-pro-exp-03-25",
            generation_config=generation_config,
            safety_settings=safety_settings
        )

        # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’é©åˆ‡ãªå½¢å¼ã«å¤‰æ›
        chat_history = []
        for msg in st.session_state.messages:
            chat_history.append({"role": msg["role"], "parts": [msg["content"]]})

        # ãƒãƒ£ãƒƒãƒˆã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’é–‹å§‹
        chat = model.start_chat(history=chat_history)

        # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦è¿½åŠ 
        context_with_prompt = f"{system_prompt}\n\n{user_input}"

        # AIã®å¿œç­”ã‚’å–å¾—
        with st.spinner("Gemini is typing ..."):
            try:
                response = chat.send_message(context_with_prompt)
                response_text = response.text

                # AIã®å¿œç­”ã‚’ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã¨ç”»é¢ã«è¿½åŠ 
                st.session_state.messages.append({"role": "model", "content": response_text})
                with st.chat_message("assistant"):
                    st.markdown(response_text)
            except Exception as e:
                st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")

# ãƒ¡ã‚¤ãƒ³é–¢æ•°ã‚’å®Ÿè¡Œ
if __name__ == "__main__":
    main()
